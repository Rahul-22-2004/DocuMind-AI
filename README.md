# ğŸ“š AI Document Assistant

AI-powered **Retrieval-Augmented Generation (RAG)** application that lets you **upload documents** (PDF, text, images) and **chat** with them to get **source-backed answers**.
Built with **Flask** (backend) + **Streamlit Premium UI** (frontend) + **FAISS** (vector database) + **Gemini** (LLM).

---

## **âœ¨ Features**

- ğŸ“‚ **File Uploads** â†’ Supports PDFs, TXT, Markdown, and images (PNG, JPG, TIFF).
- ğŸ§  **RAG-Powered Chat** â†’ Ask questions & get AI-generated answers from your uploaded documents.
- ğŸ” **Semantic Search** â†’ Uses **FAISS** + **Google Gemini embeddings** for relevant retrieval.
- ğŸ–¼ï¸ **Automatic OCR** â†’ Extracts text from scanned PDFs and images using **Tesseract**.
- ğŸ“Œ **Source Citations** â†’ Every answer includes references to document names & page numbers.
- âš¡ **Streamlit Premium UI** â†’ Modern chat interface with:

  - WhatsApp-style chat bubbles
  - Avatars & timestamps
  - Collapsible citations panel
  - Dark mode support

---

## **ğŸ› ï¸ Tech Stack**

| Layer          | Technology                                  |
| -------------- | ------------------------------------------- |
| **Frontend**   | Streamlit (Premium UI)                      |
| **Backend**    | Flask (Python)                              |
| **Vector DB**  | FAISS                                       |
| **LLM**        | Google Gemini / MiniLM                      |
| **OCR**        | Tesseract                                   |
| **Embeddings** | Google Generative AI / SentenceTransformers |

---

## **ğŸ“¦ Project Structure**

```
AI-DOCUMENT-ASSISTANT/
â”‚â”€â”€ app.py                # Flask backend (RAG logic, OCR, embeddings, FAISS)
â”‚â”€â”€ streamlit_app.py      # Streamlit premium frontend
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ input_data/           # Uploaded files and vector indexes
â”‚â”€â”€ README.md             # Documentation
â”‚â”€â”€ .env                  # Environment variables (API keys, config)
â””â”€â”€ .venv/                # Virtual environment (optional)
```

---

## **âš¡ Setup & Installation**

### **1. Clone the Repository**

```bash
git clone https://github.com/Rahul-22-2004/DocuMind-AI.git
cd ai-document-assistant
```

### **2. Create & Activate Virtual Environment** _(optional but recommended)_

```bash
python -m venv .venv
# On Windows:
.venv\Scripts\activate
# On Mac/Linux:
source .venv/bin/activate
```

### **3. Install Dependencies**

```bash
pip install -r requirements.txt
```

### **4. Configure Environment Variables**

Create a **`.env`** file in the project root and add:

```env
GOOGLE_API_KEY=your_google_api_key
EMBEDDING_BACKEND=gemini   # or minilm
TESSERACT_CMD=C:\Program Files\Tesseract-OCR\tesseract.exe
PORT=8000
FE_PORT=8501
```

---

## **ğŸš€ Running the Application**

We need **two terminals** â€” one for the **Flask backend** and one for the **Streamlit frontend**.

### **1. Start Flask Backend**

```bash
python app.py
```

- Backend runs at: **[http://localhost:8000](http://localhost:8000)**

### **2. Start Streamlit Frontend**

```bash
streamlit run streamlit_app.py
```

- Streamlit UI opens at: **[http://localhost:8501](http://localhost:8501)**

---

## **ğŸ§© How to Use**

### **Step 1 â†’ Check Backend Status**

- On the Streamlit UI, the **Backend Status** panel will confirm the connection.

### **Step 2 â†’ Upload Files**

- Go to the **ğŸ“‚ Upload & Index** section.
- Drag & drop **PDFs, TXT, Markdown, or Images**.
- Click **ğŸ“‘ Index Documents** or **ğŸ–¼ï¸ Index Images**.

### **Step 3 â†’ Chat with Your Documents**

- Navigate to the **ğŸ’¬ Chat** section.
- Ask a question â†’ click **Send** or press **Enter**.
- Get **AI-generated answers** + **citations**.

---

## **ğŸ“Œ Citations Example**

> **Answer:**
> The loan repayment period is **24 months**.

**Citations:**

- ğŸ“„ `policy_doc` (p.5) â€” policy.pdf
- ğŸ“„ `guidelines` (p.2) â€” loan_rules.pdf

---

## **âš™ï¸ Top-K Documents to Search**

- **Top-K** = Number of most relevant document chunks retrieved from FAISS.
- Default = `5` â†’ balanced speed & accuracy.
- Adjust it using the slider in Streamlit UI:

  - `Top-K = 3` â†’ Faster but may miss info.
  - `Top-K = 8` â†’ More complete answers but slower.

---

## **ğŸ§  RAG Workflow**

```
User Question â†’ Convert to Embedding â†’ Search FAISS â†’ Retrieve Top-K Chunks â†’
Send Context + Question to Gemini â†’ Generate Answer â†’ Show with Citations
```

---

## **ğŸ§ª Testing API Endpoints**

### **Health Check**

```bash
curl http://localhost:8000/health
```

### **Upload Docs**

```bash
curl -X POST -F "files=@sample.pdf" http://localhost:8000/upload_docs
```

### **Chat**

```bash
curl -X POST http://localhost:8000/chat \
     -H "Content-Type: application/json" \
     -d '{"question": "What is the policy rate?"}'
```

---

## **ğŸ› ï¸ Troubleshooting**

| Issue                      | Fix                                               |
| -------------------------- | ------------------------------------------------- |
| **Tesseract not found**    | Update `TESSERACT_CMD` in `.env`                  |
| **Backend not connecting** | Ensure Flask is running on **port 8000**          |
| **No answers returned**    | Increase **Top-K** slider                         |
| **Slow responses**         | Reduce Top-K or switch `EMBEDDING_BACKEND=minilm` |

---

## **ğŸŒŸ Future Enhancements**

- âœ… Real-time streaming answers (ChatGPT-style typing effect)
- âœ… Highlighting relevant text passages
- âœ… Save chat history per session
- âœ… Deploy on **AWS / GCP / Azure**

---

## **ğŸš€ Quick Start**

```bash
# Start backend
python app.py

# Start frontend
streamlit run streamlit_app.py
```

Then open â†’ **[http://localhost:8501](http://localhost:8501)**

---

## **ğŸ”— Connect with Me**

ğŸ“§ Email: [rahuldgowda2004@example.com]
